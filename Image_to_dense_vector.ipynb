{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import itertools\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity  \n",
    "from sklearn.metrics import pairwise_distances\n",
    "from matplotlib import gridspec\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "#Deep-Learning Library\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.graph_objs import Scatter, Layout\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started\n",
      "asins and datagen done\n",
      "Model settled\n",
      "Found 1000 images belonging to 1 classes.\n",
      "Genrator work finish\n",
      "For loop ended\n",
      "<keras.preprocessing.image.DirectoryIterator object at 0x000000471B681CC0>\n",
      "training start\n",
      "training finised\n",
      "reshape the trained vector\n",
      "Trainning done\n",
      "npy file saved\n",
      "2305.7393515661142 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = '16k_images/'\n",
    "nb_train_samples = 1000\n",
    "epochs = 50\n",
    "batch_size = 1\n",
    "print(\"Started\")\n",
    "\n",
    "def save_bottlebeck_features():\n",
    "    \n",
    "    #Function to compute VGG-16 CNN for image feature extraction.\n",
    "        \n",
    "    asins = []\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    print(\"asins and datagen done\")                                                \n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "    print(\"Model settled\")\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    print(\"Genrator work finish\")\n",
    "    for i in generator.filenames:\n",
    "        asins.append(i[2:-5])\n",
    "        \n",
    "    print(\"For loop ended\")\n",
    "    print(generator)\n",
    "    print(\"training start\")\n",
    "    bottleneck_features_train = model.predict_generator(generator, nb_train_samples // batch_size)\n",
    "    print(\"training finised\")\n",
    "    print(\"reshape the trained vector\")\n",
    "    bottleneck_features_train = bottleneck_features_train.reshape((1000,25088))\n",
    "    print(\"Trainning done\")\n",
    "    np.save(open('data_1_cnn_features.npy', 'wb'), bottleneck_features_train)\n",
    "    np.save(open('data_1_cnn_feature_asins.npy', 'wb'), np.array(asins))\n",
    "    print(\"npy file saved\")\n",
    "\n",
    "save_bottlebeck_features()\n",
    "\n",
    "print(time.clock() - start_time, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
